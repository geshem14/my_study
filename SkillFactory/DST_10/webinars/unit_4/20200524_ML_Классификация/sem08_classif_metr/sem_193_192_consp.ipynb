{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 193 Метрики классификации! "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "X_train = [ [ 4, 140 ],   y_train = [ 1,\n",
    "            [ 1, 100 ],               0,\n",
    "            [ 2, 180 ]]               1 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Упражнение 2 \n",
    "\n",
    "y_test = [ 1, 0, 1, 1, 0 ]  # реальность\n",
    "y_pred = [ 0, 0, 1, 1 ,1 ]  # прогноз \n",
    "         [ -, +, +, +, - ]  # Accuracy (доля правильных ответов) = 3/5 = 0.6\n",
    "\n",
    "# 95 - 1\n",
    "# 5 - 0 \n",
    "# Модель: говорит, y_pred = 1 для всех объектов \n",
    "# Accuracy = ?  0.95\n",
    "\n",
    "# 1. Accuracy - очень чувствительна к дисбалансу классво \n",
    "# 2. Ошибка может быть разной: было 0, мы скали 1 \n",
    "#                              было 1, мы сказали 0 \n",
    "# Accuracy не улавливает разницы => нужны новые метрики! \n",
    "\n",
    "# Precision и Recall \n",
    "\n",
    "# Матрица ошибок: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|    матрица ошибок      | $y = 1$ | $y = 0$|\n",
    "|:-------------:|:-------------:|:-----:|\n",
    "|$\\hat y = 1$|  $2$   | $1$  |\n",
    "|$\\hat y = 0$|  $1$   | $1$  |\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precision (точность) - когда я предсказал 1, сколько раз я угадал \n",
    "# 2/(2 + 1) = 2/3 = 0.66\n",
    "\n",
    "# Recall (полнота) - сколько вообще реальных 1 я нашёл \n",
    "# 2/(2 + 1) = 2/3 = 0.66 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Упражнение 3\n",
    "\n",
    "y_test = [  1,   0,   0,   1,    0 ]  # реальность\n",
    "p_pred = [ 0.7, 0.2, 0.3, 0.25, 0.1]  # P(y = 1)\n",
    "\n",
    "# Чтобы сделать прогноз меток выбирают порог t\n",
    "# Если p_pred >= t => прогнозируем 1\n",
    "# Пример 1: t = 0.5 \n",
    "y_pred = [  1,   0,    0,    0,    0 ]\n",
    "\n",
    "# Пример 2: t = 0.3\n",
    "y_pred = [  1,   0,    1,    0,    0 ]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Посчитаем ROC-AUC \n",
    "\n",
    "    y_test   p_pred = P(y_test = 1)\n",
    "      1        0.3\n",
    "      0        0.5\n",
    "      \n",
    "      1        0.7\n",
    "      \n",
    " 0.7 > 0.5 - хорошая пара из 0 и 1 (верно упорядочили)\n",
    " 0.3 < 0.5 - плохая пара из 0 и 1  (неверно упорядочили)\n",
    " \n",
    "ROC-AUC - доля верно упорядоченных пар из 0 и 1 \n",
    "\n",
    "y_test = [  1,   0,   0,   1,    0 ]  # реальность\n",
    "p_pred = [ 0.7, 0.2, 0.3, 0.25, 0.1]  # P(y = 1)\n",
    "\n",
    "2 единицы, 3 нуля => 3*2 = 6 пар \n",
    "\n",
    "0.7  0.2 +\n",
    "     0.3 +\n",
    "     0.1 +\n",
    "0.25 0.2 +\n",
    "     0.3 -\n",
    "     0.1 +\n",
    "\n",
    "ROC_AUC = 5/6  (вероятность того, что случайные объекты 1 и 0 из выборки будут правильно отсортированы нашей моделью) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 192 Метрики классификации!  "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "X_train = [ [30, 100],   y_train = [1,  # 1 - собака, 0 - другое\n",
    "            [10, 255],              0,\n",
    "            [15, 230]]              0] "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## Упражнение 2 \n",
    "\n",
    "y_test = [ 1, 0, 1, 1, 0 ]  # реальность\n",
    "y_pred = [ 0, 0, 1, 1 ,1 ]  # прогноз из какой-то модели \n",
    "           -  +  +  +  - \n",
    "           \n",
    "Доля правильных ответов (accuracy) = 3/5 = 0.6 \n",
    "\n",
    "Проблема 1: чувствительна к дисбалансу в выборке \n",
    "\n",
    "y = 1 в реальности 95 \n",
    "y = 0 в реальности 5 \n",
    "\n",
    "тупо прогнозируем везде 1, Accuracy = 0.95\n",
    "\n",
    "Решение: делать поправку на баланс\n",
    "q0 = 0.95 - accuracy, полученное наивным прогнозом (все объекты относим к самому частому классу)\n",
    "\n",
    "Понимаем, что accuracy принимает значение от 0.95 до 1\n",
    "\n",
    "Проблема 2: метрика не воспринимает то, что ошибки могут быть разного рода\n",
    "\n",
    "ошибка 1 рода: сказали, что будет 1, но в релальности был 0\n",
    "ошибка 2 рода: сказали, что будет 0, но в реальности была 1\n",
    "\n",
    "Обычно хочется понимать насколько велика каждая из этих двух ошибок => Precision (точность) и Recall (полнота)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "y_test = [ 1, 0, 1, 1, 0 ]  # реальность\n",
    "y_pred = [ 0, 0, 1, 1 ,1 ]  # прогноз из какой-то модели "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| матрица ошибок | $y = 0$       | $y = 1$  |\n",
    "|:--------------:|:-------------:|:--------:|\n",
    "| $\\hat y = 0$   | $1$ | $1$ |\n",
    "| $\\hat y = 1$   | $1$      |   $2$  |\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "precision = 2/(2 + 1) = 2/3 = 0.66  (точность) \n",
    "Сколько объектов я обозвал 1, и они правда оказались 1 \n",
    "\n",
    "recall = 2/(2 + 1) = 2/3 = 0.66 (полнота)\n",
    "То сколько 1 из вообще существующих 1 я нашёл"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## Упражнение 3 \n",
    "\n",
    "y_test = [  1,   0,   0,   1,    0 ]  # реальность\n",
    "p_pred = [ 0.7, 0.2, 0.3, 0.25, 0.1]  # P(y = 1)\n",
    "\n",
    "Когда вероятности спрогнозированы, выбирают порог t\n",
    "y_pred = 1, если p_pred >= t \n",
    "\n",
    "Пример: t = 0.3\n",
    "y_pred = [  1,   0,   1,   0,    0]\n",
    "\n",
    "Пример t = 0.5\n",
    "y_pred = [  1,   0,   0,   0,    0]\n",
    "\n",
    "\n",
    "Проблема 1: как выбрать порог? \n",
    "Проблема 2: метрики Accuracy, Recall, Precision - чувствительны к тому, какой порог взят => а как вообще тогда модели сравнивать между собой? "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Метрики ROC-AUC, PR-AUC\n",
    "\n",
    "y_test = [  1,   0,   0,   1,    0 ]  # реальность\n",
    "p_pred = [ 0.7, 0.2, 0.3, 0.25, 0.1]  # P(y = 1)\n",
    "\n",
    "       P(y = 1)\n",
    "y = 1     0.7      0.7 > 0.2 - правильно упорядочили\n",
    "y = 0     0.2\n",
    "\n",
    "y = 1     0.7      0.7 < 0.9 - неправильно упорядочили\n",
    "y = 0     0.9\n",
    "\n",
    "ROC-AUC говорит: \"А давайте посчитаем долю пар, где мы сделали правильное упорядочивание!\" \n",
    "\n",
    "1- 2 штуки, 0 - 3 штуки \n",
    "посмотреть на  пары из 0 и 1, то есть на  2*3 = 6 пар \n",
    "\n",
    "\n",
    " 1    0 \n",
    "0.7  0.2  +\n",
    "     0.3  +\n",
    "     0.1  +\n",
    "0.25 0.2  +\n",
    "     0.3  -\n",
    "     0.1  +\n",
    "     \n",
    "ROC_AUC = 5/6 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Заголовок\n",
    "\n",
    "Можно делать [гиперссылки.](http://konvut.github.io/k50articles/)\n",
    "\n",
    "Я очень люблю торт, но он калорийный и я толстею. Надо бегать. \n",
    "\n",
    "$$\n",
    "x + y = 2^2\n",
    "$$\n",
    "\n",
    "\n",
    "![картинка с человеком, который страдает](https://thumbs.gfycat.com/PreciousDenseChrysomelid-size_restricted.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
