{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Решение для задания 3.4.2\n",
    "### Задание 3.4.2\n",
    "Найдите следующий шаг градиентного спуска.  \n",
    "Текущая модель: $y=x^2$.  \n",
    "Обучающая выборка (см. код)  \n",
    "Темп обучения (learning rate): 1/6  \n",
    "Ответ будет выглядеть как $y= kx + b$, где k и b вы считаете самостоятельно.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# анимация решения\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "plt.style.use('seaborn-paper')\n",
    "\n",
    "sz = 2\n",
    "x = np.array([1,2]) \n",
    "y = np.array([2,5]) \n",
    "\n",
    "# задаём начальные случайные значения коэффициентам линейной регрессии \n",
    "w_0 = 0.0\n",
    "w_1 = 2.0\n",
    "\n",
    "# задаем шаг градиентного спуска\n",
    "alpha = 1/6\n",
    "# количество итераций\n",
    "n_iteration = 10\n",
    "\n",
    "w= np.zeros((sz,n_iteration))\n",
    "grad= np.zeros((sz,n_iteration+1))\n",
    "grad[0][0]=0\n",
    "grad[0][1]=0\n",
    "\n",
    "# основной цикл\n",
    "for i in range(n_iteration):\n",
    "            # рассчитываем результирующий массив с текущими коэффициентами w_0 и w_1\n",
    "            # на основе обучающей выборки \n",
    "            y_hat = w_0 + w_1 * x\n",
    "\n",
    "            # 1. определяем лосс\n",
    "            # считаем отклонение нового результата от обучающего:\n",
    "            error = (y - y_hat)\n",
    "\n",
    "            # 2. считаем градиенты (вспоминая формулу производной)\n",
    "            # для коэффициента w_0\n",
    "            grad_w_0 = -2 * error.mean()\n",
    "\n",
    "            # для коэффициента w_1\n",
    "            grad_w_1 = -2 * (x * error).mean()\n",
    "\n",
    "            # 3. обновляем параметры, используя шаг градиентного спуска, \n",
    "            # предварительно сохраняя предыдущие значения\n",
    "            w[0][i]= w_0\n",
    "            w[1][i]= w_1\n",
    "            grad[0][i+1]= grad_w_0\n",
    "            grad[1][i+1]= grad_w_1\n",
    "            w_0 = w_0 - alpha * grad_w_0\n",
    "            w_1 = w_1 - alpha * grad_w_1\n",
    "\n",
    "print(w)\n",
    " \n",
    "fig = plt.figure()\n",
    "ax = plt.axes(xlim=(0, 3), ylim=(0, 6))\n",
    "line, = ax.plot([], [], lw=6)\n",
    "text_iter = ax.text(0.02, 0.95, '', transform=ax.transAxes)\n",
    "text_func = ax.text(0.02, 0.90, '', transform=ax.transAxes)\n",
    "text_grad_w_0 = ax.text(0.02, 0.85, '', transform=ax.transAxes)\n",
    "text_grad_w_1 = ax.text(0.02, 0.80, '', transform=ax.transAxes)\n",
    "text_alpha = ax.text(0.02, 0.75, '', transform=ax.transAxes)\n",
    "ax.scatter (x, y, color='orange', s=100, marker='o')\n",
    "text_alpha.set_text(f'шаг (alfa) = {round(alpha,3)}')\n",
    "\n",
    "text_iter1 = ax.text(0.65, 0.20, '', transform=ax.transAxes)\n",
    "text_func1 = ax.text(0.65, 0.15, '', transform=ax.transAxes)\n",
    "text_grad_w_0_iter1 = ax.text(0.65, 0.10, '', transform=ax.transAxes)\n",
    "text_grad_w_1_iter1= ax.text(0.65, 0.05, '', transform=ax.transAxes)\n",
    "\n",
    " \n",
    "def init():\n",
    "    line.set_data([], [])\n",
    "    return line,\n",
    "\n",
    "def animate(i):\n",
    "    x = np.linspace(0, 3, 1000)\n",
    "    y = w[0][i]+w[1][i]*x\n",
    "    line.set_data(x, y)\n",
    "    text_iter.set_text(f'{i} итерация')\n",
    "    text_func.set_text(f'y = {round(w[1][i],3)}*x + {round(w[0][i],3)}')\n",
    "    text_grad_w_0.set_text(f'grad_w_0 = {round(grad[0][i],3)}')\n",
    "    text_grad_w_1.set_text(f'grad_w_1 = {round(grad[1][i],3)}')\n",
    "    if i >0:\n",
    "        text_iter1.set_text(f'1 итерация')\n",
    "        text_func1.set_text(f'y = {round(w[1][1],3)}*x + {round(w[0][1],3)}')\n",
    "        text_grad_w_0_iter1.set_text(f'grad_w_0 = {round(grad[0][1],3)}')\n",
    "        text_grad_w_1_iter1.set_text(f'grad_w_1 = {round(grad[1][1],3)}')\n",
    "        \n",
    "    return line,\n",
    " \n",
    "simpleGradientDescentForLinReg_anim = FuncAnimation(fig, animate, init_func=init,\n",
    "                               frames=n_iteration, interval=1400, blit=True)\n",
    " \n",
    " \n",
    "simpleGradientDescentForLinReg_anim.save('simpleGradientDescentForLinReg_anim.gif', writer='imagemagick')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ниже приведен код для градиентного спуска\n",
    "import numpy as np\n",
    "\n",
    "sz = 2\n",
    "x = np.array([1,2]) \n",
    "y = np.array([2,5]) \n",
    "\n",
    "# задаём начальные случайные значения коэффициентам линейной регрессии \n",
    "w_0 = 0.0\n",
    "w_1 = 2.0\n",
    "\n",
    "# задаем шаг градиентного спуска\n",
    "alpha = 1/6\n",
    "# количество итераций\n",
    "n_iteration = 10\n",
    "\n",
    "# основной цикл\n",
    "for i in range(n_iteration):\n",
    "    # рассчитываем результирующий массив с текущими коэффициентами w_0 и w_1\n",
    "    # на основе обучающей выборки \n",
    "    y_hat = w_0 + w_1 * x\n",
    "\n",
    "    # 1. определяем функцию потерь как ошибку\n",
    "    # считаем отклонение нового результата от обучающего:\n",
    "    error = (y - y_hat)\n",
    "\n",
    "    # 2. считаем градиенты (вспоминая формулу производной)\n",
    "    # для коэффициента w_0\n",
    "    grad_w_0 = -2 * error.mean()\n",
    "    # для коэффициента w_1\n",
    "    grad_w_1 = -2 * (x * error).mean()\n",
    "\n",
    "    # 3. обновляем параметры, используя шаг градиентного спуска, \n",
    "    print(i,w_0,w_1)\n",
    "    w_0 = w_0 - alpha * grad_w_0\n",
    "    w_1 = w_1 - alpha * grad_w_1"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}