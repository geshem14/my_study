\documentclass[12pt,fleqn]{article}
\usepackage{vkCourseML}
\hypersetup{unicode=true}
%\usepackage[a4paper]{geometry}
\usepackage[hyphenbreaks]{breakurl}

\interfootnotelinepenalty=10000

\begin{document}
\title{Лекция 8\\Бэггинг, случайные леса и разложение ошибки на~смещение~и~разброс}
\author{Е.\,А.\,Соколов\\ФКН ВШЭ}
\maketitle

При обсуждении решающих деревьев мы упомянули, что они могут
восстанавливать очень сложные закономерности,
но при этом неустойчивы к малейшим изменениям в данных.
Из-за этого сами по себе деревья не очень хороши,
но при этом, как оказывается, при объединении в~\emph{композицию}
они показывают очень хорошие результаты.
Одним из подходов к построению композиций является~\emph{бэггинг},
который независимо строит несколько моделей и усредняет их ответы.
На данной лекции мы изучим инструмент, который поможет нам в анализе бэггинга~---
декомпозицию ошибки на компоненты смещения и разброса~(bias-variance decomposition)~---
а затем перейдем к самим методам.
Также существует другой подход к построению композиций, называемый~\emph{бустингом},
который строит модели последовательно, и каждая следующая модель исправляет ошибки предыдущей.
О таких методах речь пойдёт уже на следующих лекциях.

\section{Бутстрап}
Рассмотрим простой пример построения композиции алгоритмов.
Пусть дана конечная выборка~$X = (x_i, y_i)$ с вещественными ответами.
Будем решать задачу линейной регрессии.
Сгенерируем подвыборку с помощью~\emph{бутстрапа}.
Равномерно возьмем из выборки~$\ell$ объектов с возвращением.
Отметим, что из-за возвращения среди них окажутся повторы.
Обозначим новую выборку через~$X_1$.
Повторив процедуру~$N$ раз, сгенерируем~$N$ подвыборок~$X_1, \dots, X_N$.
Обучим по каждой из них линейную модель регрессии,
получив~\emph{базовые алгоритмы}~$b_1(x), \dots, b_N(x)$.

Предположим, что существует истинная функция ответа для всех объектов~$y(x)$,
а также задано распределение на объектах~$p(x)$.
В этом случае мы можем записать ошибку каждой функции регрессии
\[
    \eps_j(x) = b_j(x) - y(x),
    \qquad
    j = 1, \dots, N,
\]
и записать матожидание среднеквадратичной ошибки
\[
    \EE_x (b_j(x) - y(x))^2
    =
    \EE_x \eps_j^2(x).
\]
Средняя ошибка построенных функций регрессии имеет вид
\[
    E_1
    =
    \frac{1}{N}
    \sum_{j = 1}^{N}
    \EE_x \eps_j^2(x).
\]
Предположим, что ошибки несмещены и некоррелированы:
\begin{align*}
    &\EE_x \eps_j(x) = 0;\\
    &\EE_x \eps_i(x) \eps_j(x) = 0,
    \quad
    i \neq j.
\end{align*}

Построим теперь новую функцию регрессии,
которая будет усреднять ответы построенных нами функций:
\[
    a(x) = \frac{1}{N} \sum_{j = 1}^{N} b_j(x).
\]
Найдем ее среднеквадратичную ошибку:
\begin{align*}
    E_N
    &=
    \EE_x \Biggl(
        \frac{1}{N} \sum_{j = 1}^{n} b_j(x)
        -
        y(x)
    \Biggr)^2
    =\\
    &=
    \EE_x \Biggl(
        \frac{1}{N} \sum_{j = 1}^{N} \eps_j(x)
    \Biggr)^2
    =\\
    &=
    \frac{1}{N^2}
    \EE_x \Biggl(
        \sum_{j = 1}^{N} \eps_j^2(x)
        +
        \underbrace{\sum_{i \neq j} \eps_i(x) \eps_j(x)}_{=0}
    \Biggr)
    =\\
    &=
    \frac{1}{N} E_1.
\end{align*}
Таким образом, усреднение ответов позволило уменьшить средний квадрат ошибки в~$N$ раз!

Следует отметить, что рассмотренный нами пример не очень применим на практике,
поскольку мы сделали предположение о некоррелированности ошибок, что редко выполняется.
Если это предположение неверно, то уменьшение ошибки оказывается не таким значительным.
Позже мы рассмотрим более сложные методы объединения алгоритмов в композицию,
которые позволяют добиться высокого качества в реальных задачах.

\section{Bias-Variance decomposition}
Допустим, у нас есть некоторая выборка, на которой линейные методы
работают лучше решающих деревьев с точки зрения ошибки
на контроле.
Почему это так? Чем можно объяснить превосходство определенного метода обучения?
Оказывается, ошибка любой модели складывается из трех факторов:
сложности самой выборки, сходства модели с истинной зависимостью ответов от объектов
в выборке, и богатства семейства, из которого выбирается конкретная модель.
Между этими факторами существует некоторый баланс, и уменьшение одного
из них приводит к увеличению другого.
Такое разложение ошибки носит название разложения на смещение и разброс,
и его формальным выводом мы сейчас займемся.

%\subsection{Разложение в общем виде}
Пусть задана выборка~$X = (x_i, y_i)_{i = 1}^{\ell}$
с вещественными ответами~$y_i \in \RR$~(рассматриваем задачу регрессии).
Будем считать, что на пространстве всех объектов и ответов~$\XX \times \YY$ существует
распределение~$p(x, y)$, из которого сгенерирована выборка~$X$ и ответы на ней.

Рассмотрим квадратичную функцию потерь
\[
    L(y, a)
    =
    \bigl(
        y - a(x)
    \bigr)^2
\]
и соответствующий ей~\emph{среднеквадратичный риск}
\[
    R(a)
    =
    \EE_{x, y}\Bigl[
        \bigl(
            y - a(x)
        \bigr)^2
    \Bigr]
    =
    \int_\XX
    \int_\YY
        p(x, y)
        \bigl(
            y - a(x)
        \bigr)^2
    dx
    dy.
\]
Данный функционал усредняет ошибку модели в каждой точке пространства~$x$ и для каждого
возможного ответа~$y$, причём вклад пары~$(x, y)$, по сути,
пропорционален вероятности получить её в выборке~$p(x, y)$.
Разумеется, на практике мы не можем вычислить данный функционал,
поскольку распределение~$p(x, y)$ неизвестно.
Тем не менее, в теории он позволяет измерить качество модели
на всех возможных объектах, а не только на обучающей выборке.

\subsection{Минимум среднеквадратичного риска}
Покажем, что минимум среднеквадратичного риска достигается
на функции, возвращающей условное матожидание ответа при фиксированном объекте:
\[
    a_*(x)
    =
    \EE[y \cond x]
    =
    \int_{\YY}
        y p(y \cond x)
    dy
    =
    \argmin_{a} R(a).
\]

Преобразуем функцию потерь:
\begin{align*}
    L(y, a(x))
    &=
    (y - a(x))^2
    =
    (y - \EE (y \cond x) + \EE (y \cond x) - a(x))^2
    =\\
    &=
    (y - \EE (y \cond x))^2 +
        2 \bigl(y - \EE (y \cond x)\bigr) \bigl(\EE (y \cond x) - a(x)\bigr) +
        (\EE (y \cond x) - a(x))^2.
\end{align*}
Подставляя ее в функционал среднеквадратичного риска, получаем:
\begin{align*}
    R(a)
    &=
    \EE_{x, y} L(y, a(x))
    =\\
    &=
    \EE_{x, y} (y - \EE (y \cond x))^2 +
        \EE_{x, y} (\EE (y \cond x) - a(x))^2 + \\
        &+ 2 \EE_{x, y} \bigl(y - \EE (y \cond x)\bigr)
            \bigl(\EE (y \cond x) - a(x)\bigr).
\end{align*}
Разберемся сначала с последним слагаемым.
Перейдём от матожидания~$\EE_{x, y} [f(x, y)]$
к цепочке матожиданий
\[
    \EE_{x} \EE_{y} [f(x, y) \cond x]
    =
    \int_\XX \left(
        \int_\YY
            f(x, y) p(y \cond x) dy
        \right)
        p(x) dx
\]
и заметим, что величина~$\bigl(\EE (y \cond x) - a(x)\bigr)$
не зависит от~$y$, и поэтому ее можно вынести за матожидание по~$y$:
\begin{align*}
    &\EE_{x} \EE_y \Bigl[ \bigl(y - \EE (y \cond x)\bigr)
            \bigl(\EE (y \cond x) - a(x)\bigr)
            \cond
            x
        \Bigr]
    =\\
    &=
    \EE_x \Bigl(
        \bigl(\EE (y \cond x) - a(x)\bigr)
        \EE_y \Bigl[
            \bigl(y - \EE (y \cond x)\bigr)
            \cond
            x
        \Bigr]
    \Bigr)
    =\\
    &=
    \EE_x \Bigl(
        \bigl(\EE (y \cond x) - a(x)\bigr)
        \bigl(\EE (y \cond x) - \EE (y \cond x)\bigr)
    \Bigr)
    =\\
    &= 0
\end{align*}
Получаем, что функционал среднеквадратичного риска имеет вид
\[
    R(a)
    =
    \EE_{x, y} (y - \EE (y \cond x))^2 +
    \EE_{x, y} (\EE (y \cond x) - a(x))^2.
\]
От алгоритма~$a(x)$ зависит только второе слагаемое,
и оно достигает своего минимума, если~$a(x) = \EE (y \cond x)$.
Таким образом, оптимальная модель регрессии
для квадратичной функции потерь имеет вид
\[
    a_*(x) = \EE (y \cond x)
    =
    \int_\YY y p(y \cond x) dy.
\]
Иными словами, мы должны провести <<взвешенное голосование>>
по всем возможным ответам, причем вес ответа равен его
апостериорной вероятности.

\subsection{Ошибка метода обучения}
Для того, чтобы построить идеальную функцию регрессии, необходимо
знать распределение на объектах и ответах~$p(x, y)$, что, как правило, невозможно.
На практике вместо этого выбирается некоторый~\emph{метод обучения}~$\mu: (\XX \times \YY)^\ell \to \AA$,
который произвольной обучающей выборке ставит в соответствие
некоторый алгоритм из семейства~$\AA$.
В качестве меры качества метода обучения можно взять усредненный по всем выборкам
среднеквадратичный риск алгоритма, выбранного методом~$\mu$ по выборке:
\begin{align}
\label{eq:learnMethodLoss}
    L(\mu)
    &=
    \EE_{X} \Bigl[
        \EE_{x, y} \Bigl[
            \bigl(
            y - \mu(X)(x)
            \bigr)^2
        \Bigr]
    \Bigr]
    =\\ \notag
    &=
    \int_{(\XX \times \YY)^\ell}
    \int_{\XX \times \YY}
        \bigl(
        y - \mu(X)(x)
        \bigr)^2
        p(x, y)
        \prod_{i = 1}^{\ell}
            p(x_i, y_i)
    dx dy
    dx_1 dy_1
    \dots
    dx_\ell dy_\ell
    .
\end{align}
Здесь матожидание~$\EE_{X} [\cdot]$ берется по всем
возможным выборкам~$\{(x_1, y_1), \dots, (x_\ell, y_\ell)\}$
из распределения~$\prod_{i = 1}^{\ell} p(x_i, y_i)$.

Обратим внимание, что результатом применения метода обучения~$\mu(X)$ к выборке~$X$ является модель,
поэтому правильно писать~$\mu(X)(x)$.
Но это довольно громоздкая запись, поэтому будем везде дальше писать просто~$\mu(X)$,
но не будем забывать, что это функция, зависящая от объекта~$x$.

Выше мы показали, что среднеквадратичный риск на фиксированной
выборке~$X$ можно расписать как
\[
    \EE_{x, y} \Bigl[
        \bigl(
            y - \mu(X)
        \bigr)^2
    \Bigr]
    =
    \EE_{x, y} \Bigl[
        \bigl(
            y - \EE[y \cond x]
        \bigr)^2
    \Bigr]
    +
    \EE_{x, y} \Bigl[
        \bigl(
            \EE[y \cond x]
            -
            \mu(X)
        \bigr)^2
    \Bigr].
\]
Подставим это представление в~\eqref{eq:learnMethodLoss}:
\begin{align}
    L(\mu)
    &=
    \EE_{X} \Bigl[
        \underbrace{
            \EE_{x, y} \Bigl[
                \bigl(
                    y - \EE[y \cond x]
                \bigr)^2
            \Bigr]
        }_{\text{не зависит от~$X$}}
        +
        \EE_{x, y} \Bigl[
            \bigl(
                \EE[y \cond x]
                -
                \mu(X)
            \bigr)^2
        \Bigr]
    \Bigr]
    =\notag\\
    &=
    \EE_{x, y} \Bigl[
        \bigl(
            y - \EE[y \cond x]
        \bigr)^2
    \Bigr]
    +
    \EE_{x, y} \Bigl[
        \EE_{X} \Bigl[
            \bigl(
                \EE[y \cond x]
                -
                \mu(X)
            \bigr)^2
        \Bigr]
    \Bigr]. \label{eq:decomp1}
\end{align}
Преобразуем второе слагаемое:
\begin{align}
    \EE_{x, y} \Bigl[
        \EE_{X} &\Bigl[
            \bigl(
                \EE[y \cond x]
                -
                \mu(X)
            \bigr)^2
        \Bigr]
    \Bigr]
    =\notag\\
    =
    \EE_{x, y} &\Bigl[
        \EE_{X} \Bigl[
            \bigl(
                \EE[y \cond x]
                -
                \EE_{X} \bigl[ \mu(X) \bigr]
                +
                \EE_{X} \bigl[ \mu(X) \bigr]
                -
                \mu(X)
            \bigr)^2
        \Bigr]
    \Bigr]
    =\notag\\
    =
    \EE_{x, y} &\Bigl[
        \EE_{X} \Bigl[
            \underbrace{
                \bigl(
                    \EE[y \cond x]
                    -
                    \EE_{X} \bigl[ \mu(X) \bigr]
                \bigr)^2
            }_{\text{не зависит от~$X$}}
        \Bigr]
    \Bigr]
    +
    \EE_{x, y} \Bigl[
        \EE_{X} \Bigl[
            \bigl(
                \EE_{X} \bigl[ \mu(X) \bigr]
                -
                \mu(X)
            \bigr)^2
        \Bigr]
    \Bigr]
    +\notag\\
    &+
    2
    \EE_{x, y} \Bigl[
        \EE_{X} \Bigl[
            \bigl(
                \EE[y \cond x]
                -
                \EE_{X} \bigl[ \mu(X) \bigr]
            \bigr)
            \bigl(
                \EE_{X} \bigl[ \mu(X) \bigr]
                -
                \mu(X)
            \bigr)
        \Bigr]
    \Bigr]. \label{eq:decomp2}
\end{align}
Покажем, что последнее слагаемое обращается в нуль:
\begin{align*}
    \EE_{X} \Bigl[&
        \bigl(
            \EE[y \cond x]
            -
            \EE_{X} \bigl[ \mu(X) \bigr]
        \bigr)
        \bigl(
            \EE_{X} \bigl[ \mu(X) \bigr]
            -
            \mu(X)
        \bigr)
    \Bigr]
    =\\
    &=
    \bigl(
        \EE[y \cond x]
        -
        \EE_{X} \bigl[ \mu(X) \bigr]
    \bigr)
    \EE_{X} \Bigl[
        \EE_{X} \bigl[ \mu(X) \bigr]
        -
        \mu(X)
    \Bigr]
    =\\
    &=
    \bigl(
        \EE[y \cond x]
        -
        \EE_{X} \bigl[ \mu(X) \bigr]
    \bigr)
    \Bigl[
        \EE_{X} \bigl[ \mu(X) \bigr]
        -
        \EE_{X} \bigl[ \mu(X) \bigr]
    \Bigr]
    =\\
    &=
    0.
\end{align*}
Учитывая это, подставим~\eqref{eq:decomp2} в~\eqref{eq:decomp1}:
\begin{align}
    &L(\mu)
    =
    \underbrace{
        \EE_{x, y} \Bigl[
            \bigl(
                y - \EE[y \cond x]
            \bigr)^2
        \Bigr]
    }_{\text{шум}}
    +\notag\\
    &+
    \underbrace{
        \EE_{x} \Bigl[
            \bigl(
                \EE_{X} \bigl[ \mu(X) \bigr]
                -
                \EE[y \cond x]
            \bigr)^2
        \Bigr]
    }_{\text{смещение}}
    +
    \underbrace{
        \EE_{x} \Bigl[
            \EE_{X} \Bigl[
                \bigl(
                    \mu(X)
                    -
                    \EE_{X} \bigl[ \mu(X) \bigr]
                \bigr)^2
            \Bigr]
        \Bigr]
    }_{\text{разброс}}. \label{eq:biasVarDecomp}
\end{align}
Рассмотрим подробнее компоненты полученного разложения ошибки.
Первая компонента характеризует~\emph{шум} в данных и равна ошибке идеального алгоритма.
Невозможно построить алгоритм, имеющий меньшую среднеквадратичную ошибку.
Вторая компонента характеризует~\emph{смещение~(bias)} метода обучения,
то есть отклонение среднего ответа обученного алгоритма
от ответа идеального алгоритма.
Третья компонента характеризует~\emph{дисперсию~(variance)},
то есть разброс ответов обученных алгоритмов относительно среднего ответа.

Смещение показывает, насколько хорошо с помощью данных метода обучения и
семейства алгоритмов можно приблизить оптимальный алгоритм.
Как правило, смещение маленькое у сложных семейств~(например,
у деревьев) и большое у простых семейств~(например, линейных классификаторов).
Дисперсия показывает, насколько сильно может изменяться ответ
обученного алгоритма в зависимости от выборки~--- иными словами,
она характеризует чувствительность метода обучения
к изменениям в выборке.
Как правило, простые семейства имеют маленькую дисперсию,
а сложные семейства~--- большую дисперсию.

\begin{figure}[t]
    \centering
    \includegraphics[width=0.6\linewidth]{tradeoff.eps}
    \caption{Иллюстрация сдвига и разброса для различных моделей.}
    \label{fig:tradeoff}
\end{figure}

На рис.~\ref{fig:tradeoff} изображены модели с различными сдвигом и разбросом.
Модели изображены синими точками, одна точка соответствует модели,
обученной по одной из возможных обучающих выборок.
Каждый круг характеризует качество модели~--- чем ближе точка к центру,
тем меньше ошибок на контрольной выборке достигает данный алгоритм.
Видно, что большой сдвиг соответствует тому, что в среднем точки не попадают в центр,
то есть в среднем они не соответствуют лучшей модели.
Большой разброс означает, что модель может попасть по качеству куда угодно~---
как в центр, так и в область с большой ошибкой.

\paragraph{Разложение для произвольной функции потерь.}
Разложение ошибки на три компоненты, которое мы только что вывели, верно
только для квадратичной функции потерь.
Существуют более общие формы этого разложения~\cite{domingos00unified},
которые состоят из трёх компонент с аналогичным смыслом,
поэтому можно утверждать, что для большинства распространённых функций потерь
ошибка метода обучения складывается из шума, смещения и разброса;
значит, и дальнейшие рассуждения про изменение этих компонент в композициях
также можно обобщить на другие функции потерь~(например, на индикатор ошибки классификации).

\section{Бэггинг}
Пусть имеется некоторый метод обучения~$\mu(X)$.
Построим на его основе метод~$\tilde \mu(X)$, который
генерирует случайную подвыборку~$\tilde X$ с помощью бутстрапа
и подает ее на вход метода~$\mu$: $\tilde \mu(X) = \mu(\tilde X)$.
Напомним, что бутстрап представляет собой сэмплирование~$\ell$ объектов из выборки
с возвращением, в результате чего некоторые объекты выбираются несколько
раз, а некоторые~--- ни разу.
Помещение нескольких копий одного объекта в бутстрапированную выборку
соответствует выставлению веса при данном объекте~--- соответствующее ему
слагаемое несколько раз войдет в функционал, и поэтому штраф
за ошибку на нем будет больше.

В~\emph{бэггинге~(bagging, bootstrap aggregation)} предлагается обучить некоторое
число алгоритмов~$b_n(x)$ с помощью метода~$\tilde \mu$, и построить итоговую композицию
как среднее данных базовых алгоритмов:
\[
    a_N(x)
    =
    \frac{1}{N}
    \sum_{n = 1}^{N}
        b_n(x)
    =
    \frac{1}{N}
    \sum_{n = 1}^{N}
        \tilde \mu(X)(x).
\]
Заметим, что в методе обучения для бэггинга появляется ещё один источник случайности~---
взятие подвыборки.
Чтобы функционал качества~$L(\mu)$ был детерминированным,
мы будем далее считать, что матожидание~$\EE_X [\cdot]$ берётся
не только по всем обучающим выборкам~$X$,
но ещё и по всем возможным подвыборкам~$\tilde X$,
получаемым с помощью бутстрапа.
Это вполне логичное обобщение, поскольку данное матожидание
вводится в функционал именно для учёта случайностей,
связанных с процедурой обучения модели.

Найдём смещение из разложения~\eqref{eq:biasVarDecomp} для бэггинга:
\begin{align*}
    \EE_{x, y} &\Bigl[
        \Bigl(
            \EE_{X} \Bigl[
                \frac{1}{N}
                \sum_{n = 1}^{N}
                    \tilde \mu(X)(x)
            \Bigr]
            -
            \EE[y \cond x]
        \Bigr)^2
    \Bigr]
    =\\
    &=
    \EE_{x, y} \Bigl[
        \Bigl(
                \frac{1}{N}
                \sum_{n = 1}^{N}
                    \EE_X[ \tilde \mu(X)(x) ]
            -
            \EE[y \cond x]
        \Bigr)^2
    \Bigr]
    =\\
    &=
    \EE_{x, y} \Bigl[
        \bigl(
            \EE_{X} \bigl[
                \tilde \mu(X)(x)
            \bigr]
            -
            \EE[y \cond x]
        \bigr)^2
    \Bigr].
\end{align*}
Мы получили, что смещение композиции, полученной с помощью бэггинга,
совпадает со смещением одного базового алгоритма.
Таким образом, бэггинг не ухудшает смещенность модели.

Теперь перейдём к разбросу.
Запишем выражение для дисперсии композиции,
обученной с помощью бэггинга:
\[
    \EE_{x, y} \Bigl[
        \EE_{X} \Bigl[
            \Bigl(
                \frac{1}{N}
                \sum_{n = 1}^{N}
                    \tilde \mu(X)(x)
                -
                \EE_{X} \Bigl[
                    \frac{1}{N}
                    \sum_{n = 1}^{N}
                        \tilde \mu(X)(x)
                \Bigr]
            \Bigr)^2
        \Bigr]
    \Bigr].
\]
Рассмотрим выражение, стоящее под матожиданиями:
\begin{align*}
    \Bigl(
        \frac{1}{N}&
        \sum_{n = 1}^{N}
            \tilde \mu(X)(x)
        -
        \EE_{X} \Bigl[
            \frac{1}{N}
            \sum_{n = 1}^{N}
                \tilde \mu(X)(x)
        \Bigr]
    \Bigr)^2
    =\\
    &=
    \frac{1}{N^2}
    \Bigl(
        \sum_{n = 1}^{N} \Bigl[
                \tilde \mu(X)(x)
                -
                \EE_{X} \bigl[
                    \tilde \mu(X)(x)
                \bigr]
        \Bigr]
    \Bigr)^2
    =\\
    &=
    \frac{1}{N^2}
    \sum_{n = 1}^{N} \Bigl(
        \tilde \mu(X)(x)
        -
        \EE_{X} \bigl[
            \tilde \mu(X)(x)
        \bigr]
    \Bigr)^2 +\\
    &\text{\hspace{0.5cm}}+
    \frac{1}{N^2}
    \sum_{n_1 \neq n_2} \Bigl(
        \tilde \mu(X)(x)
        -
        \EE_{X} \bigl[
            \tilde \mu(X)(x)
        \bigr]
    \Bigr)
    \Bigl(
        \tilde \mu(X)(x)
        -
        \EE_{X} \bigl[
            \tilde \mu(X)(x)
        \bigr]
    \Bigr)
\end{align*}
%Первое слагаемое~--- это сумма дисперсий базовых алгоритмов,
%второе~--- сумма ковариаций попарно различных базовых алгоритмов.
Возьмем теперь матожидания от этого выражения, учитывая, что все базовые
алгоритмы одинаково распределены относительно~$X$:
\begin{align*}
    &\EE_{x, y} \Bigl[
        \EE_{X} \Bigl[
            \frac{1}{N^2}
            \sum_{n = 1}^{N} \Bigl(
                \tilde \mu(X)(x)
                -
                \EE_{X} \bigl[
                    \tilde \mu(X)(x)
                \bigr]
            \Bigr)^2
            +\\
            &\text{\hspace{0.5cm}}+
            \frac{1}{N^2}
            \sum_{n_1 \neq n_2} \Bigl(
                \tilde \mu(X)(x)
                -
                \EE_{X} \bigl[
                    \tilde \mu(X)(x)
                \bigr]
            \Bigr)
            \Bigl(
                \tilde \mu(X)(x)
                -
                \EE_{X} \bigl[
                    \tilde \mu(X)(x)
                \bigr]
            \Bigr)
        \Bigr]
    \Bigr]
    =\\
    &=
    \frac{1}{N^2}
    \EE_{x, y} \Bigl[
        \EE_{X} \Bigl[
            \sum_{n = 1}^{N} \Bigl(
                \tilde \mu(X)(x)
                -
                \EE_{X} \bigl[
                    \tilde \mu(X)(x)
                \bigr]
            \Bigr)^2
        \Bigr]
    \Bigr]
    +\\
    &\text{\hspace{0.5cm}}+
    \frac{1}{N^2}
    \EE_{x, y} \Bigl[
        \EE_{X} \Bigl[
            \sum_{n_1 \neq n_2} \Bigl(
                \tilde \mu(X)(x)
                -
                \EE_{X} \bigl[
                    \tilde \mu(X)(x)
                \bigr]
            \Bigr)
            \times\\
            &\text{\hspace{2cm}}\times
            \Bigl(
                \tilde \mu(X)(x)
                -
                \EE_{X} \bigl[
                    \tilde \mu(X)(x)
                \bigr]
            \Bigr)
        \Bigr]
    \Bigr]
    =\\
    &=
    \frac{1}{N}
    \EE_{x, y} \Bigl[
        \EE_{X} \Bigl[
            \Bigl(
                \tilde \mu(X)(x)
                -
                \EE_{X} \bigl[
                    \tilde \mu(X)(x)
                \bigr]
            \Bigr)^2
        \Bigr]
    \Bigr]
    +\\
    &\text{\hspace{0.5cm}}+
    \frac{N(N-1)}{N^2}
    \EE_{x, y} \Bigl[
        \EE_{X} \Bigl[
            \Bigl(
                \tilde \mu(X)(x)
                -
                \EE_{X} \bigl[
                    \tilde \mu(X)(x)
                \bigr]
            \Bigr)
            \times\\
            &\text{\hspace{2cm}}\times
            \Bigl(
                \tilde \mu(X)(x)
                -
                \EE_{X} \bigl[
                    \tilde \mu(X)(x)
                \bigr]
            \Bigr)
        \Bigr]
    \Bigr]
\end{align*}
Первое слагаемое~--- это дисперсия одного базового алгоритма,
деленная на длину композиции~$N$.
Второе~--- ковариация между двумя базовыми алгоритмами.
Мы видим, что если базовые алгоритмы некоррелированы,
то дисперсия композиции в~$N$ раз меньше дисперсии отдельных алгоритмов.
Если же корреляция имеет место, то уменьшение дисперсии может быть гораздо
менее существенным.

\subsection{Случайные леса}

\begin{algorithm}[t]
\caption{Random Forest}
\label{alg:rf}
    \begin{algorithmic}[1]
        \FOR{$n = 1, \dots, N$}
            \STATE Сгенерировать выборку~$\tilde X_n$ с помощью бутстрэпа
            \STATE Построить решающее дерево~$b_n(x)$ по выборке~$\tilde X_n$:
                \begin{itemize}
                    \item дерево строится, пока в каждом листе не окажется не более~$n_{\min}$ объектов
                    \item при каждом разбиении сначала выбирается~$m$ случайных
                        признаков из~$p$, и оптимальное разделение ищется только среди них
                \end{itemize}
        \ENDFOR
        \STATE Вернуть композицию~$a_N(x) = \frac{1}{N} \sum_{n = 1}^{N} b_n(x)$
    \end{algorithmic}
\end{algorithm}

Как мы выяснили, бэггинг позволяет объединить несмещенные,
но чувствительные к обучающей выборке алгоритмы в несмещенную
композицию с низкой дисперсией.
Хорошим семейством базовых алгоритмов здесь являются решающие деревья~---
они достаточно сложны и могут достигать нулевой ошибки
на любой выборке~(следовательно, имеют низкое смещение),
но в то же время легко переобучаются.

Метод~\emph{случайных лесов}~\cite{breiman01randomforest} основан на бэггинге над решающими деревьями,
см. алгоритм~\ref{alg:rf}.
Выше мы отметили, что бэггинг сильнее уменьшает дисперсию
базовых алгоритмов, если они слабо коррелированы.
В случайных лесах корреляция между деревьями понижается путем рандомизации
по двум направлениям: по объектам и по признакам.
Во-первых, каждое дерево обучается по бутстрапированной подвыборке.
Во-вторых, в каждой вершине разбиение ищется по подмножеству признаков.
Вспомним, что при построении дерева последовательно происходит
разделение вершин до тех пор, пока не будет достигнуто идеальное
качество на обучении.
Каждая вершина разбивает выборку по одному из признаков
относительно некоторого порога.
В случайных лесах признак, по которому производится разбиение,
выбирается не из всех возможных признаков, а лишь из
их случайного подмножества размера~$m$.

Рекомендуется в задачах классификации брать~$m = \lfloor \sqrt{d} \rfloor$,
а в задачах регрессии~--- $m = \lfloor d/3 \rfloor$,
где~$d$~--- число признаков.
Также рекомендуется в задачах классификации строить каждое дерево до тех
пор, пока в каждом листе не окажется по одному объекту,
а в задачах регрессии~--- пока в каждом листе не окажется по пять объектов.

Случайные леса~--- один из самых сильных методов построения композиций.
На практике он может работать немного хуже градиентного бустинга,
но при этом он гораздо более прост в реализации.

\subsubsection{Out-of-Bag}
Каждое дерево в случайном лесе обучается по подмножеству объектов.
Это значит, что те объекты, которые не вошли в бутстрапированную выборку~$X_n$ дерева~$b_n$,
по сути являются контрольными для данного дерева.
Значит, мы можем для каждого объекта~$x_i$ найти деревья,
которые были обучены без него, и вычислить по их ответам out-of-bag-ошибку:
\[
    \text{OOB}
    =
    \sum_{i = 1}^{\ell}
        L \left(
            y_i,
            \frac{1}{\sum_{n = 1}^{N} [x_i \notin X_n]}
            \sum_{n = 1}^{N}
                [x_i \notin X_n] b_n(x_i)
        \right),
\]
где~$L(y, z)$~--- функция потерь.
Можно показать, что по мере увеличения числа деревьев~$N$
данная оценка стремится к leave-one-out-оценке,
но при этом существенно проще для вычисления.

\subsection{Связь с метрическими методами}
Случайные леса, по сути, осуществляют предсказание для объекта на основе
меток похожих объектов из обучения.
Схожесть объектов при этом тем выше, чем чаще эти объекты оказываются
в одном и том же листе дерева.
Покажем это формально.

Рассмотрим задачу регрессии с квадратичной функцией потерь.
Пусть~$T_n(x)$~--- номер листа~$n$-го дерева из случайного леса,
в который попадает объект~$x$.
Ответ дерева на объекте~$x$ равен среднему ответу по всем
обучающим объектам, которые попали в лист~$T_n(x)$.
Это можно записать как
\[
    b_n(x)
    =
    \sum_{i = 1}^{\ell}
        w_n(x, x_i) y_i,
\]
где
\[
    w_n(x, x_i)
    =
    \frac{
        [T_n(x) = T_n(x_i)]
    }{
        \sum_{j = 1}^{\ell}
            [T_n(x) = T_n(x_j)]
    }.
\]
Тогда ответ композиции равен
\[
    a_N(x)
    =
    \frac{1}{N}
    \sum_{n = 1}^{N}
    \sum_{i = 1}^{\ell}
        w_n(x, x_i) y_i
    =
    \sum_{i = 1}^{\ell} \left(
        \frac{1}{N}
        \sum_{n = 1}^{N}
        w_n(x, x_i)
    \right)
    y_i.
\]
Видно, что ответ случайного леса представляет собой сумму ответов всех
объектов обучения с некоторыми весами,
причём данные веса измеряют сходство объектов~$x$ и~$x_i$
на основе того, сколько раз они оказались в одном и том же листе.
Таким образом, случайный лес позволяет ввести некоторую функцию расстояния на объектах.
Как мы узнаем позже, на этом принципе основан целый класс~\emph{метрических}
методов, наиболее популярным представителем которых является метод~$k$ ближайших соседей.

Отметим, что номер листа~$T_n(x)$, в который попал объект, сам по себе является ценным признаком.
Достаточно неплохо работает подход, в котором по выборке обучается композиция
из небольшого числа деревьев с помощью случайного леса или градиентного бустинга,
а затем к ней добавляются категориальные признаки~$T_1(x), T_2(x), \dots, T_N(x)$.
Новые признаки являются результатом нелинейного разбиения пространства
и несут в себе информацию о сходстве объектов.

\begin{thebibliography}{1}
\bibitem{hastie01esl}
    \emph{Hastie, T., Tibshirani, R., Friedman, J.} (2001).
    The Elements of Statistical Learning.~//
    Springer, New York.

\bibitem{domingos00unified}
    \emph{Domingos, Pedro} (2000).
    A Unified Bias-Variance Decomposition and its Applications.~//
    In Proc. 17th International Conf. on Machine Learning.

\bibitem{breiman01randomforest}
    \emph{Breiman, Leo} (2001).
    Random Forests.~//
    Machine Learning, 45(1), 5--32.
\end{thebibliography}
\end{document}
